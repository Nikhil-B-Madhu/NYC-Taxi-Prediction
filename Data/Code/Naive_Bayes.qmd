---
title: "Naive_Bayes"
author: "Nikhil_B M"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r}
library(tidyverse)  # data manipulation and visualization
library(modelr)     # provides easy pipeline modeling functions
library(broom)      # helps to tidy up model outputs
library(ggplot2)
```

```{r}
library(naivebayes)
#Loading required packages
#install.packages('tidyverse')
library(tidyverse)
#install.packages('ggplot2')
library(ggplot2)
#install.packages('caret')
#library(caret)
#install.packages('caretEnsemble')
#library(caretEnsemble)
#install.packages('psych')
library(psych)
#install.packages('Amelia')
#library(Amelia)
#install.packages('mice')
#library(mice)
#install.packages('GGally')
#library(GGally)
library(e1071)
library(caret)
```

```{r}
travel_data<-read.csv("D:/2_MS_in_DS/2nd_Semester/Machine_Learning/Project/Data/NYC_Taxi_Data/nyc_taxi_Jan_2022_naive_bayes_sample.csv")
travel_data

str(travel_data)

travel_data$total_amount = as.factor(travel_data$total_amount)

str(travel_data)

travel_data
```

```{r}
StudentDataFile="C:/Users/Nikhi/Documents/Machine_Learning/StudentSummerProgramDataClean_DT.csv"
head(StudentDF<-read.csv(StudentDataFile))
```

```{r}
## Record Data..................
## MAKE test and train data
#(Size <- (as.integer(nrow(StudentDF)/4)))  ## Test will be 1/4 of the data
#(SAMPLE <- sample(nrow(StudentDF), Size))

#(DF_Test_Student<-StudentDF[SAMPLE, ])
#(DF_Train_Student<-StudentDF[-SAMPLE, ])

(Size <- (as.integer(nrow(travel_data)/4)))  ## Test will be 1/4 of the data
(SAMPLE <- sample(nrow(travel_data), Size))

(DF_Test_travel<-travel_data[SAMPLE, ])
(DF_Train_travel<-travel_data[-SAMPLE, ])

```

Their- Decision is label Mine: total_amount

```{r}
##
## REMOVE the labels and KEEP THEM
##   
## 
#str(DF_Test_Student$Decision)  ## Notice that the label is called "Decision" and
## is correctly set to type FACTOR. This is IMPORTANT!!
#str(DF_Train_Student$Decision)  ## GOOD! Here "Decision" is also type FACTOR
##Check balance of test dataset
#table(DF_Test_Student$Decision)

#typeof(DF_Test_travel)

str(DF_Test_travel$total_amount)  ## Notice that the label is called "total_amount" and
## is correctly set to type FACTOR. This is IMPORTANT!!
str(DF_Train_travel$total_amount)  ## GOOD! Here "total_amount" is also type FACTOR 
##Check balance of test dataset
table(DF_Test_travel$total_amount)

```

```{r}

##################################### REMOVE AND SAVE LABELS...
## Copy the Labels
(DF_Test_travel_Labels <- DF_Test_travel$total_amount)
## Remove the labels
DF_Test_travel_NL<-DF_Test_travel[ , -which(names(DF_Test_travel) %in% c("total_amount"))]
(DF_Test_travel_NL[1:5, 1:5])
## Check size
(ncol(DF_Test_travel_NL))
#(DF_Test_Student_NL)
## Train...--------------------------------
## Copy the Labels
(DF_Train_travel_Labels <- DF_Train_travel$total_amount)
## Remove the labels
DF_Train_travel_NL<-DF_Train_travel[ , -which(names(DF_Train_travel) %in% c("total_amount"))]
(DF_Train_travel_NL[1:5, 1:5])
## Check size
(ncol(DF_Train_travel_NL))
#(DF_Train_Student_NL)

#DF_Test_travel_NL
#write.csv(DF_Test_travel_NL, "D:/2_MS_in_DS/2nd_Semester/Machine_Learning/Project/Data/NYC_Taxi_Data/nyc_taxi_Jan_2022_naive_bayes_sample_test.csv", row.names=FALSE)


#DF_Train_travel_NL
#DF_Train_travel_Labels
#DF_Train_travel


#write.csv(DF_Train_travel, "D:/2_MS_in_DS/2nd_Semester/Machine_Learning/Project/Data/NYC_Taxi_Data/nyc_taxi_Jan_2022_naive_bayes_sample_train_labels.csv", row.names=FALSE)
```


```{r}



# Load the required package
library(ggcorrplot)

# Load the dataset
data <-DF_Train_travel_NL

# Select the relevant columns
cols <- c("trip_distance", "passenger_count", "payment_type", "extra", "tip_amount", "fare_amount", "trip_times")
data <- data[, cols]

# Calculate the correlation matrix
corr_matrix <- cor(data)

# Create a correlation plot
ggcorrplot(corr_matrix, hc.order = TRUE, type = "lower", lab = TRUE, lab_size = 3, title = "Correlation Plot")

```


```{r}
##############################################################
##
##                         NAIVE BAYES
##
###############################################################

## ----------------------------
## For Record data, we have:
##-----------------------------
## DF_Test_Student_NL  ## Testset
## DF_Train_Student_NL  ## Training set
## Label name is "Decision"
## Test labels:
## DF_Test_Student_Labels
## DF_Train_Student_Labels
######################################

## Just FYI......................if memory or overflow issues....
## memory.limit()
#data=DF_Train[,1:5000]
#(data[1:5, 1:5])
##


##########################################################
## Record Data----------------------------
#######################################################
(NB_e1071_travel_with_laplace<-naiveBayes(DF_Train_travel_NL, DF_Train_travel_Labels, laplace = 1))
NB_e1071_Pred_travel_with_laplace <- predict(NB_e1071_travel_with_laplace, DF_Test_travel_NL)
(NB_e1071_Pred_travel_with_laplace)



(NB_e1071_travel_without_laplace<-naiveBayes(DF_Train_travel_NL, DF_Train_travel_Labels, laplace = 0))
NB_e1071_Pred_travel_without_laplace <- predict(NB_e1071_travel_without_laplace, DF_Test_travel_NL)
(NB_e1071_Pred_travel_without_laplace)
```

Frequency distribution of the prediction:

```{r}
plot(NB_e1071_Pred_travel_without_laplace, xlab="Total Amount Categories", ylab = "Frequency", main = "Prediction of Different Categories of Total Amount")
```

With-out Laplace:

Train - Confusion Matrix and Accuracy

```{r}
#Confusion Matrix
NB_e1071_Pred_travel_train_without_laplace <- predict(NB_e1071_travel_without_laplace, DF_Train_travel_NL)
(tab1_without_laplace <- table(NB_e1071_Pred_travel_train_without_laplace,DF_Train_travel_Labels))

```

```{r}
conf_matrix  <- caret::confusionMatrix(NB_e1071_Pred_travel_train_without_laplace,DF_Train_travel_Labels)

conf_matrix
```

"""heatmap_data \<- as.matrix(conf_matrix\$table) heatmap(heatmap_data, Rowv=NA, Colv=NA, col = c('red','blue'))"""

```{r}

library(ggplot2)
library(gplots)
heatmap_data <- as.matrix(conf_matrix$table)

heatmap.2(heatmap_data, Rowv = NA, Colv = NA,
          col = colorRampPalette(c("white", "orange", "red"))(100),
          trace = "none",
          main = "Confusion Matrix",
          labRow = rownames(heatmap_data),
          labCol = colnames(heatmap_data),
          cexRow = 0.8,
          cexCol = 0.8,
          margins = c(5, 10),
          keysize = 1.2,
          key.title = NA,
          symkey = FALSE,
          density.info = "none",
          notecol = "black",
          notecex = 0.6,
          cellnote = heatmap_data)
```

```{r}
(Tain_error_without_laplace <- 1 - sum(diag(tab1_without_laplace)) / sum(tab1_without_laplace))
(Tain_accuracy_without_laplace <- (1- Tain_error_without_laplace) * 100 )
```

Misclassification is around 12.4%. Training model accuracy is around 87.6%.

Test - Confusion Matrix and Accuracy

```{r}
#Confusion Matrix
NB_e1071_Pred_travel_test_without_laplace <- predict(NB_e1071_travel_without_laplace, DF_Test_travel_NL)
(tab2_without_laplace <- table(NB_e1071_Pred_travel_test_without_laplace,DF_Test_travel_Labels))
```


```{r}
cm <- confusionMatrix(NB_e1071_Pred_travel_test_without_laplace,DF_Test_travel_Labels)
cm
```
```{r}

library(ggplot2)
library(gplots)
heatmap_data <- as.matrix(cm$table)

heatmap.2(heatmap_data, Rowv = NA, Colv = NA,
          col = colorRampPalette(c("white", "orange", "red"))(100),
          trace = "none",
          main = "Confusion Matrix",
          labRow = rownames(heatmap_data),
          labCol = colnames(heatmap_data),
          cexRow = 0.8,
          cexCol = 0.8,
          margins = c(5, 10),
          keysize = 1.2,
          key.title = NA,
          symkey = FALSE,
          density.info = "none",
          notecol = "black",
          notecex = 0.6,
          cellnote = heatmap_data)
```
```{r}
(Test_error_without_laplace <- 1 - sum(diag(tab2_without_laplace)) / sum(tab2_without_laplace))
(Test_accuracy_without_laplace <- (1- Test_error_without_laplace) * 100 )
```

Misclassification is around 11.8%. Training model accuracy is around 88.2%.

## --------------------------------------------------------------------------------------------------------------------

With Laplace:

Frequency distribution of the prediction:

```{r}
plot(NB_e1071_Pred_travel_with_laplace)
```

Train - Confusion Matrix and Accuracy

```{r}
#Confusion Matrix
NB_e1071_Pred_travel_train_with_laplace <- predict(NB_e1071_travel_with_laplace, DF_Train_travel_NL)
(tab1_with_laplace <- table(NB_e1071_Pred_travel_train_with_laplace,DF_Train_travel_Labels))
```

```{r}
confusionMatrix(NB_e1071_Pred_travel_train_with_laplace,DF_Train_travel_Labels)
```

```{r}
(Tain_error_with_laplace <- 1 - sum(diag(tab1_with_laplace)) / sum(tab1_with_laplace))
(Tain_accuracy_with_laplace <- (1- Tain_error_with_laplace) * 100 )
```

Misclassification is around 12.4%. Training model accuracy is around 87.6%.

Test - Confusion Matrix and Accuracy

```{r}
#Confusion Matrix
NB_e1071_Pred_travel_test_with_laplace <- predict(NB_e1071_travel_with_laplace, DF_Test_travel_NL)
(tab2_with_laplace <- table(NB_e1071_Pred_travel_test_with_laplace,DF_Test_travel_Labels))
```

```{r}
confusionMatrix(NB_e1071_Pred_travel_test_with_laplace,DF_Test_travel_Labels)
```

```{r}
(Test_error_with_laplace <- 1 - sum(diag(tab2_with_laplace)) / sum(tab2_with_laplace))
(Test_accuracy_with_laplace <- (1- Test_error_with_laplace) * 100 )
```

Misclassification is around 11.8%. Training model accuracy is around 88.2%.
